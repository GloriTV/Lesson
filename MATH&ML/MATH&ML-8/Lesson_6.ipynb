{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Продалжаем здессь [DecisionTree_CART_3](DecisionTree_CART_3.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Созданные функции рание\n",
    "* find_candidates_for_thresholds(x, y) ищит экстремум(вкаком месте меняется)\n",
    "    1. сортирует X по возврастанию и удаляет дубликаты\n",
    "    2. ищет среднее значение X между соседних значений и удоляет nan\n",
    "    3. формируем Y по индексу оставшихся X\n",
    "    4. находим изменения Y (да=1 нет=0)\n",
    "    5. фильтруем X по значению изменения Y=1\n",
    "\n",
    "* split(X, y, split_params) делит выборку на правую илевую по критерию 'split_params'\n",
    "\n",
    "* calculate_weighted_impurity(X, y, split_params, criterion) производит подсчет 'criterion' разделенной выборки с помощью 'split(X, y, split_params)'\n",
    "\n",
    "* best_split(X, y, criterion) ищит наилучшие разделение выборки \n",
    "    1. перебираем по столбцам X и отправляем столбец в 'find_candidates_for_thresholds(x, y)'\n",
    "    2. полученное из 'find_candidates_for_thresholds(x, y)' перебираем и отпровляем в 'calculate_weighted_impurity(X, y, split_params, criterion)'\n",
    "    3. из полученных значений 'calculate_weighted_impurity(X, y, split_params, criterion)' ищим наименьшее и сохраняем его значения и параметры его получения\n",
    "    4. возвращаем параметры разбиения выборки\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_candidates_for_thresholds(x, y):\n",
    "    x = x.sort_values().drop_duplicates()\n",
    "    x_roll_mean = x.rolling(2).mean().dropna()\n",
    "    y = y[x_roll_mean.index]\n",
    "    y_roll_mean = y.diff()\n",
    "    candidates = x_roll_mean[y_roll_mean != 0]\n",
    "    return candidates.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X, y, split_params):\n",
    "    j, t = split_params\n",
    "    predicat = X.iloc[:, j] <= t # записываем True или False выполнения условия равное количеству X   \n",
    "    X_left, y_left = X[predicat], y[predicat]\n",
    "    X_right, y_right = X[~predicat], y[~predicat]\n",
    "    return X_left, y_left, X_right, y_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_impurity(X, y, split_params, criterion):\n",
    "    X_left, y_left, X_right, y_right = split(X, y, split_params)\n",
    "    N, N_left, N_right  = y.size, y_left.size, y_right.size\n",
    "    score = N_left / N * criterion(y_left) + N_right / N * criterion(y_right)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(X, y, criterion):\n",
    "    M = X.shape[1]\n",
    "    min_weighted_impurity = np.inf\n",
    "    optimal_split_params = None\n",
    "    for j in range(M):\n",
    "        thresholds = find_candidates_for_thresholds(X.iloc[:, j], y)\n",
    "        for t in thresholds:\n",
    "            split_params = (j, t)\n",
    "            weighted_impurity = calculate_weighted_impurity(X, y, split_params, criterion)\n",
    "            if weighted_impurity < min_weighted_impurity:\n",
    "                min_weighted_impurity = weighted_impurity\n",
    "                optimal_split_params = split_params\n",
    "    return optimal_split_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала создадим вспомогательный класс вершины. У него будут следующие атрибуты:\n",
    "* left — ссылка на левого потомка;\n",
    "* right — ссылка на правого потомка;\n",
    "* value — ответ алгоритма;\n",
    "* split_params — параметры разбиения (сплита);\n",
    "* impurity — неоднородность в вершине (пригодится для расчёта важности признаков);\n",
    "* samples — количество объектов, попавших в вершину;\n",
    "* is_leaf — булева переменная, которая указывает, является ли вершина листовой.\n",
    "\n",
    "По умолчанию все параметры заданы как None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, left=None, \n",
    "                 right=None, value=None, \n",
    "                 split_params=None, impurity=None,\n",
    "                 samples=None, is_leaf=False):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.split_params = split_params\n",
    "        self.value = value\n",
    "        self.impurity = impurity\n",
    "        self.samples = samples\n",
    "        self.is_leaf = is_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем эту часть в виде функции create_leaf_prediction(). Она будет принимать на вход целевую переменную y и возвращать модальное значение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf_prediction(y):\n",
    "    value = y.mode()[0]\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее введём критерий остановки. Самый базовый критерий — равенство нулю критерия информативности, рассчитанного по вершине."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopping_criterion(X, y, criterion):\n",
    "    return criterion(y) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, создадим функцию build_decision_tree(). Она будет реализовывать сам рекурсивный алгоритм построения дерева решений. Функция будет принимать на вход выборку X и y, а также критерий информативности. На выходе функции должна быть корневая вершина дерева (объект класса Node). Она будет ссылаться на своих левого и правого потомка, они в свою очередь будут ссылаться на своих потоков, и так далее до самых листьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decision_tree(X, y, criterion):\n",
    "    if stopping_criterion(X, y, criterion):\n",
    "        value = create_leaf_prediction(y)\n",
    "        node = Node(\n",
    "            value=value, \n",
    "            impurity=criterion(y), \n",
    "            samples=y.size,\n",
    "            is_leaf=True\n",
    "        )\n",
    "    else:\n",
    "        split_params = best_split(X, y, criterion=criterion)\n",
    "        X_left, y_left, X_right, y_right = split(X, y, split_params)\n",
    "        left = build_decision_tree(X_left, y_left, criterion)\n",
    "        right = build_decision_tree(X_right, y_right, criterion)       \n",
    "        node = Node(\n",
    "            left=left, right=right, \n",
    "            split_params=split_params, \n",
    "            impurity=criterion(y), \n",
    "            samples=y.size\n",
    "        )\n",
    "    \n",
    "    return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также напишем вспомогательную функцию print_decision_tree(). Она будет принимать на вход корневую вершину дерева решений и рекурсивно выводить дерево решений в виде текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_decision_tree(node, depth=0):\n",
    "    depth += 1\n",
    "    if node.is_leaf:\n",
    "        print('   ' * depth, 'class: {}'.format(node.value))\n",
    "    else:\n",
    "        print('   ' * depth, 'feature_{} <= {:.3f}:'.format(*node.split_params))\n",
    "        print_decision_tree(node.left, depth=depth)\n",
    "        print('   ' * depth, 'feature_{} > {:.3f}:'.format(*node.split_params))\n",
    "        print_decision_tree(node.right, depth=depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте обучим наше дерево решений на игрушечном датасете о выдаче кредитов клиентам банка и напечатаем его. Напомним, что у нас есть два фактора: $x_1$ — возраст заёмщика, $x_2$ — доход заёмщика. Целевая переменная $y$ — бинарная (0 — кредит погашен, 1 — кредит не погашен)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    feature_0 <= 43.500:\n",
      "       feature_1 <= 86.000:\n",
      "          feature_0 <= 22.500:\n",
      "             feature_0 <= 19.000:\n",
      "                class: 1\n",
      "             feature_0 > 19.000:\n",
      "                class: 0\n",
      "          feature_0 > 22.500:\n",
      "             class: 1\n",
      "       feature_1 > 86.000:\n",
      "          class: 0\n",
      "    feature_0 > 43.500:\n",
      "       class: 0\n"
     ]
    }
   ],
   "source": [
    "# Объявляем функцию для вычисления энтропии\n",
    "def entropy(y):\n",
    "    p = y.value_counts(normalize=True)\n",
    "    entropy = -np.sum(p * np.log2(p))\n",
    "    return entropy\n",
    "\n",
    "# Создаём обучающую выборку\n",
    "data = pd.DataFrame({\n",
    "    'age': [17, 64, 18, 20, 38, 49, 55, 25, 29, 31],\n",
    "    'income': [25, 80, 22, 36, 37, 59, 74, 70, 33, 102],\n",
    "    'loan': [1, 0, 1, 0, 1, 0, 0, 1, 1, 0]\n",
    "})\n",
    "X = data[['age', 'income']]\n",
    "y = data['loan']\n",
    "\n",
    "# Строим дерево решений и выводим его на экран\n",
    "decision_tree = build_decision_tree(X, y, criterion=entropy)\n",
    "print_decision_tree(decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем функцию calculate_feature_importances() для расчёта относительных значимостей признаков. Она будет принимать на вход обученное дерево решений. Также у неё будет аргумент по умолчанию — массив из значимостей feature_importances. Так как функция будет рекурсивной, то при первом запуске массив нужно проинициализировать нулями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_feature_importances(node, feature_importance=None):\n",
    "    if feature_importance is None:\n",
    "        feature_importance = np.zeros(X.shape[1])\n",
    "    if node.value is None:\n",
    "        j = node.split_params[0]\n",
    "        feature_importance[j] += node.impurity * node.samples - \\\n",
    "                                 node.left.impurity * node.left.samples - \\\n",
    "                                 node.right.impurity * node.right.samples\n",
    "        calculate_feature_importances(node.left, feature_importance)\n",
    "        calculate_feature_importances(node.right, feature_importance)\n",
    "    feature_importance /= node.samples\n",
    "    feature_importance /= feature_importance.sum()\n",
    "    return feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем функцию на нашем «игрушечном» датасете о кредитах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78582905 0.21417095]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Создаем обучающую выборку\n",
    "data = pd.DataFrame({\n",
    "    'age': [17, 64, 18, 20, 38, 49, 55, 25, 29, 31],\n",
    "    'income': [25, 80, 22, 36, 37, 59, 74, 70, 33, 102],\n",
    "    'loan': [1, 0, 1, 0, 1, 0, 0, 1, 1, 0]\n",
    "})\n",
    "X = data[['age', 'income']]\n",
    "y = data['loan'] \n",
    "# Строим дерево решений и печатаем его на экран\n",
    "decision_tree = build_decision_tree(X, y, entropy)\n",
    "# Считаем информативности признаков\n",
    "print(calculate_feature_importances(decision_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78582905 0.21417095]\n"
     ]
    }
   ],
   "source": [
    "# Создаём модель дерева решений и обучаем её\n",
    "dt = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    random_state=1000 #генератор случайных чисел\n",
    ")\n",
    "dt.fit(X, y)\n",
    "# Вычисляем значения информативности признаков\n",
    "print(dt.feature_importances_)\n",
    "# [0.78582905 0.21417095]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.3\n",
    "Дано дерево решений, решающее задачу классификации людей на тех, кто зарабатывает > 50 тысяч долларов (класс 1), и тех, кто зарабатывает меньше этой суммы (класс 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20178437500000002"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=lambda a,b,c,d,e,g:a*b-c*d-e*g\n",
    "N=320\n",
    "\n",
    "f_0=f(320,0.462,227,0.273,93,0.256)\n",
    "f_1=f(93,0.256,18,0.444,75,0.191)\n",
    "f_2=f(189,0.071,127,0,62,0.2)\n",
    "n=1/320\n",
    "n*(f_0+f_1+f_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "541247ef5e2c485a853fcdfc5770898360c10253d62f064c141db27a35a34903"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
